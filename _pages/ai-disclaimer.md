---
permalink: /ai-disclaimer/
title: "AI Disclaimer"
---
I've been posting a fair bit about AI tools on this site - since early 2025 I've gone from quite skeptical to finding them extremely useful in software engineering and in many other areas.

***HOWEVER*** we need to be aware of the ethical problems and risky nature of AI as well.
{: .notice--warning}

I want to include a disclaimer in every AI post; because it's not as simple as "this is useful so we should use it" - IT doesn't exist in a bubble, we need to consider the impact on the world, on the climate, on other people, the ethical side of what we do.

First - the tools are largely built and owned by giant tech companies that are pushing these hard into every corner of our lives, and every penny we spend on these tools goes to these companies. They are run by horrible tech [broligarchs](https://en.wikipedia.org/wiki/Broligarchy)[^broligarchy] whose interests are personal power and destabilising democracy, not helping the world.

Second, they consume vast amounts of power, which due to our failure to charge for [externalities](https://en.wikipedia.org/wiki/Externality), mean they are burning fossil fuels, consuming scarce water, and accelerating the climate crisis.

And thirdly, there are many signs that the funding for this is an unsustainable bubble, fueled by hype and grift and dubious practices. [Cory Doctorow](https://pluralistic.net/2025/09/27/econopocalypse/) has a great coverage of this, and [Ed Zitron](https://www.wheresyoured.at/subprimeai/) has discussed this in depth as well (though Ed is not always as informed on tech details as he should be). The concerns have even prompted a [warning from the Bank of England](https://www.theguardian.com/business/2025/oct/08/bank-of-england-warns-of-growing-risk-that-ai-bubble-could-burst) - it seems quite likely that the companies building these tools may collapse, or start charging significantly more and/or enshittifying the experience of users.

I'm still finding AI extremely useful - especially in the limited area of boosting Software Engineering, where there is less of the "plagiarism machine" and more ways to compensate for hallucinations and other LLM limitations. But we can't work in AI without keeping all these risks in mind, especially "what would we do if all the commercial tools suddenly became unavailable?"

[^broligarchy]: Thanks [Carole Cadwalla](https://broligarchy.substack.com/about) for introducing me to the very useful term [Broligarchy](https://en.wikipedia.org/wiki/Broligarchy)!